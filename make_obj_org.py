# -*- coding: utf-8 -*-
import os
import sys
import argparse
from pathlib import Path

import numpy as np
import torch
import open3d as o3d
from pytorch3d.transforms import quaternion_to_matrix

os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"
os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"

# Resolve sam-3d-objects root from ./sam-3d-objects (script dir or cwd)
_SCRIPT_DIR = Path(__file__).resolve().parent
_CWD = Path.cwd().resolve()

SAM3D_ROOT = (_SCRIPT_DIR / "sam-3d-objects").resolve()
if not SAM3D_ROOT.exists():
    SAM3D_ROOT = (_CWD / "sam-3d-objects").resolve()

assert SAM3D_ROOT.exists(), (
    f"sam-3d-objects not found.\n"
    f"Expected at: {_SCRIPT_DIR / 'sam-3d-objects'} or {_CWD / 'sam-3d-objects'}\n"
    f"Current script dir: {_SCRIPT_DIR}\n"
    f"Current working dir: {_CWD}"
)

if str(SAM3D_ROOT) not in sys.path:
    sys.path.insert(0, str(SAM3D_ROOT))

NOTEBOOK_DIR = (SAM3D_ROOT / "notebook").resolve()
assert NOTEBOOK_DIR.exists(), f"notebook dir not found: {NOTEBOOK_DIR}"
if str(NOTEBOOK_DIR) not in sys.path:
    sys.path.insert(0, str(NOTEBOOK_DIR))

from inference import Inference, load_image, load_single_mask
from sam3d_objects.data.dataset.tdfy.transforms_3d import compose_transform

tag = "hf-download"
config_path = f"/inspire/ssd/project/robot-reasoning/xiangyushun-p-xiangyushun/jiaxin/ckpts/checkpoints/{tag}/checkpoints/pipeline.yaml"
inference = Inference(config_path, compile=False)

def _to_numpy(x):
    if isinstance(x, torch.Tensor):
        return x.detach().cpu().numpy()
    return np.asarray(x)

def _extract_rgb_from_vertex_attrs(vertex_attrs, n_verts: int):
    if vertex_attrs is None:
        return None
    attrs = _to_numpy(vertex_attrs)
    if attrs.ndim != 2 or attrs.shape[0] != n_verts or attrs.shape[1] < 3:
        return None
    rgb = attrs[:, 0:3].astype(np.float32)
    return np.clip(rgb, 0.0, 1.0)

def _write_obj_with_vcolor(obj_path: str, vertices: np.ndarray, faces: np.ndarray, rgb: np.ndarray | None):
    v = np.asarray(vertices, dtype=np.float64)[:, :3]
    f = np.asarray(faces, dtype=np.int64)[:, :3]

    # normalize 1-based to 0-based if needed
    if f.size > 0 and f.min() >= 1 and f.max() <= v.shape[0]:
        f = f - 1

    with open(obj_path, "w", encoding="utf-8") as fp:
        fp.write("# Generated by make_obj_org_with_color\n")
        if rgb is not None:
            for i in range(v.shape[0]):
                fp.write(
                    f"v {v[i,0]:.6f} {v[i,1]:.6f} {v[i,2]:.6f} "
                    f"{rgb[i,0]:.6f} {rgb[i,1]:.6f} {rgb[i,2]:.6f}\n"
                )
        else:
            for i in range(v.shape[0]):
                fp.write(f"v {v[i,0]:.6f} {v[i,1]:.6f} {v[i,2]:.6f}\n")

        for i in range(f.shape[0]):
            a, b, c = int(f[i, 0]) + 1, int(f[i, 1]) + 1, int(f[i, 2]) + 1
            fp.write(f"f {a} {b} {c}\n")


def make_scene_untextured_mesh(output):
    mesh = output["mesh"][0]

    vertices = mesh.vertices.detach().cpu().numpy()
    faces = mesh.faces.detach().cpu().numpy()
    vertex_attrs = getattr(mesh, "vertex_attrs", None)

    rgb = _extract_rgb_from_vertex_attrs(vertex_attrs, n_verts=int(vertices.shape[0]))

    vertices_tensor = torch.from_numpy(vertices).float().to(output["rotation"].device)
    R_l2c = quaternion_to_matrix(output["rotation"])
    l2c_transform = compose_transform(
        scale=output["scale"],
        rotation=R_l2c,
        translation=output["translation"],
    )
    vertices_world = (
        l2c_transform.transform_points(vertices_tensor.unsqueeze(0))
        .squeeze(0)
        .cpu()
        .numpy()
    )

    o3d_mesh = o3d.geometry.TriangleMesh()
    o3d_mesh.vertices = o3d.utility.Vector3dVector(vertices_world)
    o3d_mesh.triangles = o3d.utility.Vector3iVector(faces)
    o3d_mesh.compute_vertex_normals()
    if rgb is not None:
        o3d_mesh.vertex_colors = o3d.utility.Vector3dVector(rgb.astype(np.float64))

    return vertices_world, faces, rgb, o3d_mesh


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--video_dir", type=str, required=True)
    parser.add_argument("--select_index", type=int, default=0)
    args = parser.parse_args()

    frame_dir = os.path.join(args.video_dir, "frames")
    mask_dir = os.path.join(args.video_dir, "mask_dir")

    frames = sorted([x for x in os.listdir(frame_dir) if x.endswith(".jpg") or x.endswith(".png")])
    if args.select_index >= len(frames):
        print(f"Error: select_index {args.select_index} out of range for {len(frames)} frames.")
        sys.exit(1)

    frame_name = frames[args.select_index]
    image_path = os.path.join(frame_dir, frame_name)

    print(f"Loading image: {image_path}")
    image = load_image(image_path)

    print(f"Loading mask from {mask_dir} with index {args.select_index}")
    mask = load_single_mask(mask_dir, index=args.select_index, extension=".png")

    # run model
    output = inference(image, mask, seed=42)

    vertices_world, faces, rgb, o3d_mesh = make_scene_untextured_mesh(output)

    output_path = os.path.join(args.video_dir, "obj_org.obj")
    _write_obj_with_vcolor(output_path, vertices_world, faces, rgb)
    print(f"Saved colored OBJ to {output_path}")
